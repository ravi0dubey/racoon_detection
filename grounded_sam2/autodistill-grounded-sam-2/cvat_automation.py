# -*- coding: utf-8 -*-
"""cvat_automation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NDBodJmAeUVX-qrAVCgsYLaEThD9gBLc
"""

!pip install -r requirements.txt

!git clone https://github.com/autodistill/autodistill-grounded-sam-2

import os

os.chdir('/content/autodistill-grounded-sam-2')

!pip install rf_groundingdino

from autodistill_grounded_sam_2 import GroundedSAM2
from autodistill.detection import CaptionOntology
from autodistill.utils import plot

import cv2
import numpy as np
import matplotlib.pyplot as plt
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def initialize_model(prompt):
    """
    Initialize the GroundedSAM2 model with the given prompt.

    Args:
        prompt (str): Prompt for the model.

    Returns:
        GroundedSAM2: Initialized model instance.
    """
    logging.info(f"Initializing GroundedSAM2 model with prompt: {prompt}")
    prompt_dict = {prompt: prompt}
    model = GroundedSAM2(
        ontology=CaptionOntology(prompt_dict)
    )
    logging.info("Model initialized successfully.")
    return model

def process_image(model, image_path):
    """
    Process an image file with the GroundedSAM2 model.

    Args:
        model (GroundedSAM2): Initialized model instance.
        image_path (str): Path to the image file.

    Returns:
        tuple: Original image, segmentation mask, and annotated image.
    """
    logging.info(f"Processing image: {image_path}")

    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    results = model.predict(image_path)
    logging.info(f"Prediction results: {results}")

    # Create segmentation mask
    mask = np.zeros(image.shape[:2], dtype=np.uint8)
    if isinstance(results.mask, np.ndarray):
        mask = results.mask.squeeze().astype(np.uint8) * 255

    # Create annotated image
    annotated_image = plot(
        image=image_rgb,
        classes=model.ontology.classes(),
        detections=results,
        raw=True
    )

    return image_rgb, mask, annotated_image

def plot_results(image, mask, annotated_image):
    """
    Plot the original image, segmentation mask, and annotated image.

    Args:
        image (numpy.ndarray): Original image.
        mask (numpy.ndarray): Segmentation mask.
        annotated_image (numpy.ndarray): Annotated image.
    """
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title("Original Image")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(mask, cmap='gray')
    plt.title("Segmentation Mask")
    plt.axis('off')

    plt.subplot(1, 3, 3)
    plt.imshow(annotated_image)
    plt.title("Annotated Image")
    plt.axis('off')

    plt.tight_layout()
    plt.show()

def main():
    # Initialize the model with the "racoon" prompt
    model = initialize_model("tree")

    # Process a single image
    image_path = "/content/raccoon-1.jpg"
    image, mask, annotated_image = process_image(model, image_path)

    # Plot the results
    plot_results(image, mask, annotated_image)

logging.info("Starting the application")
  main()
  logging.info("Application completed")